---
layout: post
title: Streaming json data to Big Query using Rails 6
author: ndaru
categories: ["rails", "streaming", "bigquery"]
image: https://cdn-images-1.medium.com/max/1024/0*EcHLUnNNl_2SwKkJ.png
---
<p><strong>How to stream data using job and test it using RSpec.</strong></p><p>Bigquery is SAAS using REST api to managed data warehouse which provided by google. It can be combine with mapreduce and have machine learning capability.</p><p>This topic is try to send data to bigQuery, there is any way to send data using ruby, such as:</p><pre># upload using csv<br>table.load &quot;gs://my-bucket/file-name.csv&quot;</pre><pre># load using json<br>table.insert data_rows</pre><p>For these tutorial we try to send via last one (streaming json), for complete description see <a href="https://googleapis.dev/ruby/google-cloud-bigquery/latest/index.html">this link</a></p><p><strong>Step 1: Create service account and install gemfile</strong></p><p>It assume you already install Rails 6. First of all make sure some of gem below are already insert in Gemfile.lock. rspec and webmock used for test bigquery service</p><pre>gem &#39;google-cloud-bigquery&#39;group :test do<br>  gem &#39;rspec-rails&#39;<br>  gem &#39;webmock&#39;end</pre><pre>end</pre><p>After that, install with command bundle install .</p><p>These gem using key from Service Account, before we create key, we need to define Role for these service account, since we only need to steam data and avoid alter or delete table, we register these roles:</p>
<script src="https://gist.github.com/kusumandaru/e1b3ddb34e96edd9a4a3452d060bf1c3.js"></script>
<p>Example give this roles name BigQuery Stream</p><p>Back into service account create new one, than assign role into this service,</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*EcHLUnNNl_2SwKkJ.png" /><figcaption>service account generation</figcaption></figure><p>Choose json file for key generation, save into local computer. (Securing these file, and never put these file on repository)</p><p><strong>Step 2: Create service for stream account</strong></p><p>Set environment variable on for path and project_id, also make sure credential json file not on same project, so it not accidentally push on repository.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*008l5QIKVFsRJEg3.png" /><figcaption>project ID</figcaption></figure><pre>BIGQUERY_CREDENTIAL_PATH=/path-to-file/bigquery.json<br>BIGQUERY_PROJECT_ID=bigquery-test-270003</pre><p>After that create base service file to connect to bigquery, like base.rb</p>
<script src="https://gist.github.com/kusumandaru/8fab31f9b014e3d0df18b5ff9ec66de8.js"></script>
<p>We load library bigquery also use active model for catch error on header filer</p><p>We load configuration using environment variable and initialize instance on initialise method.</p><p>Since we make base class as superclass and inheritance dataset and table id we must define on base.rb and than we load these dataset and table, after that we call method to send json data into bigquery.</p><p>We need check if table is exist on bigquery before we stream data, and than we send data into bigquery and check if response is success or not, if response file than we catch errors to show to user and return false value, otherwise we return true response.</p><p>Than we can define subclass for sent data, for example, we try send user model</p>
<script src="https://gist.github.com/kusumandaru/2d56682d521f143b9563e2b2e83a132d.js"></script>
<p>We then define DATASET_ID and TABLE_ID for these service and convert model into json using as_json method</p><p>we define shared example to mock bigquery, catch response form response and define on json for each request</p>
<script src="https://gist.github.com/kusumandaru/57de95c5248452c6e9df80d694d6678d.js"></script>
<p>and we create spec by test this class:</p>
<script src="https://gist.github.com/kusumandaru/b47f0262efc2a142ea7267d40f64359f.js"></script>
<p>For final step we create job so, streaming data running on background task</p>
<script src="https://gist.github.com/kusumandaru/a3d2fc9ec0f83531dc512ff36ff6e0b3.js"></script>
<p>We check model is exist before we send and we call service to run job</p><p>for spec test we check using these command</p>
<script src="https://gist.github.com/kusumandaru/54d21ce01b085fc575bf7382251ae27e.js"></script>
<p>And you can call by using command:</p><p>BigQuery::UserStreamJob.perform_later(some_user.id)</p><p>Check on bigquery console when data is succesfully inserted</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*a-7b53oaGAZ58qAh.png" /><figcaption>user table</figcaption></figure><img src="https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=c422ac47d520" width="1" height="1">